#!/usr/bin/env python3
"""
ç®€åŒ–çš„GPUå›¾åƒæ”¾å¤§æœåŠ¡ - å®Œå…¨ç‹¬ç«‹å®ç°
ä¸ä¾èµ–BasicSRå’ŒRealESRGANåŒ…ï¼Œç›´æ¥ä½¿ç”¨PyTorch
"""
import os
import cv2
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

class ResidualDenseBlock(nn.Module):
    """æ®‹å·®å¯†é›†å—"""
    def __init__(self, num_feat=64, num_grow_ch=32):
        super(ResidualDenseBlock, self).__init__()
        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)
        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def forward(self, x):
        x1 = self.lrelu(self.conv1(x))
        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))
        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))
        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 * 0.2 + x

class RRDB(nn.Module):
    """æ®‹å·®ä¸­çš„æ®‹å·®å¯†é›†å—"""
    def __init__(self, num_feat, num_grow_ch=32):
        super(RRDB, self).__init__()
        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)
        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)
        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)

    def forward(self, x):
        out = self.rdb1(x)
        out = self.rdb2(out)
        out = self.rdb3(out)
        return out * 0.2 + x

class SimpleRRDBNet(nn.Module):
    """ç®€åŒ–çš„RRDBNetç½‘ç»œ"""
    def __init__(self, num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4):
        super(SimpleRRDBNet, self).__init__()
        self.scale = scale
        
        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)
        self.body = nn.ModuleList([RRDB(num_feat, num_grow_ch) for _ in range(num_block)])
        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        
        # ä¸Šé‡‡æ ·å±‚
        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
        
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def forward(self, x):
        feat = self.lrelu(self.conv_first(x))
        
        body_feat = feat
        for block in self.body:
            body_feat = block(body_feat)
        
        feat = feat + self.conv_body(body_feat)
        
        # 4å€ä¸Šé‡‡æ ·
        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))
        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))
        feat = self.lrelu(self.conv_hr(feat))
        out = self.conv_last(feat)
        
        return out

class SimpleGPUUpscaler:
    """ç®€åŒ–çš„GPUå›¾åƒæ”¾å¤§æœåŠ¡"""
    
    def __init__(self, model_path, device='auto'):
        # è®¾å¤‡é€‰æ‹©
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = 'cuda'
                print(f"ğŸ® æ£€æµ‹åˆ°CUDAè®¾å¤‡: {torch.cuda.get_device_name(0)}")
                print(f"ğŸ’¾ GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            else:
                self.device = 'cpu'
                print("âš ï¸  æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUæ¨¡å¼")
        else:
            self.device = device
            
        self.model_path = model_path
        self.model = None
        self.is_initialized = False
        
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ç®€åŒ–GPUæ”¾å¤§æœåŠ¡...")
        self.initialize_model()
        
    def initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            if not os.path.exists(self.model_path):
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                return False
            
            # åˆ›å»ºæ¨¡å‹
            self.model = SimpleRRDBNet(
                num_in_ch=3, 
                num_out_ch=3, 
                num_feat=64, 
                num_block=6, 
                num_grow_ch=32, 
                scale=4
            )
            
            # åŠ è½½æƒé‡
            print("ğŸ“¦ åŠ è½½æ¨¡å‹æƒé‡...")
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # å°è¯•ä¸åŒçš„æƒé‡é”®
            if 'params_ema' in checkpoint:
                state_dict = checkpoint['params_ema']
            elif 'params' in checkpoint:
                state_dict = checkpoint['params']
            else:
                state_dict = checkpoint
            
            # è¿‡æ»¤ä¸åŒ¹é…çš„é”®
            model_dict = self.model.state_dict()
            filtered_dict = {}
            
            for k, v in state_dict.items():
                if k in model_dict and model_dict[k].shape == v.shape:
                    filtered_dict[k] = v
                else:
                    print(f"âš ï¸  è·³è¿‡ä¸åŒ¹é…çš„æƒé‡: {k}")
            
            # åŠ è½½è¿‡æ»¤åçš„æƒé‡
            self.model.load_state_dict(filtered_dict, strict=False)
            self.model.eval()
            self.model = self.model.to(self.device)
            
            # GPUä¼˜åŒ–
            if self.device == 'cuda':
                torch.backends.cudnn.benchmark = True
                # é¢„çƒ­
                dummy_input = torch.randn(1, 3, 64, 64).to(self.device)
                with torch.no_grad():
                    _ = self.model(dummy_input)
                del dummy_input
                torch.cuda.empty_cache()
                print("ğŸ”¥ GPUé¢„çƒ­å®Œæˆ")
            
            load_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.2f}ç§’")
            print(f"ğŸ“± è®¾å¤‡: {self.device}")
            if self.device == 'cuda':
                print(f"ğŸ’¾ GPUæ˜¾å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**2:.1f}MB")
            self.is_initialized = True
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def resize_image_if_needed(self, image, max_size=None):
        """æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´å›¾åƒå¤§å°"""
        h, w = image.shape[:2]
        
        if max_size is None:
            if self.device == 'cuda':
                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
                if gpu_memory_gb >= 8:
                    max_size = 1024
                elif gpu_memory_gb >= 6:
                    max_size = 768
                else:
                    max_size = 512
            else:
                max_size = 512
        
        scale_factor = min(max_size / w, max_size / h)
        
        if scale_factor < 1:
            new_w = int(w * scale_factor)
            new_h = int(h * scale_factor)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            print(f"ğŸ“ å›¾åƒç¼©æ”¾: {w}Ã—{h} â†’ {new_w}Ã—{new_h} (æœ€å¤§å¤„ç†: {max_size}px)")
        
        return image, scale_factor
    
    def enhance_image(self, img):
        """å¢å¼ºå›¾åƒ"""
        try:
            # OpenCVè¯»å–çš„æ˜¯BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # è½¬æ¢ä¸ºtensor
            img_tensor = img_rgb.astype(np.float32) / 255.0
            img_tensor = torch.from_numpy(np.transpose(img_tensor, (2, 0, 1))).float()
            img_tensor = img_tensor.unsqueeze(0).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                if self.device == 'cuda':
                    with torch.cuda.amp.autocast():
                        output = self.model(img_tensor)
                else:
                    output = self.model(img_tensor)
            
            # è½¬æ¢å›numpy (RGBæ ¼å¼)
            output = output.data.squeeze().float().cpu().clamp_(0, 1).numpy()
            output = np.transpose(output, (1, 2, 0))
            output = (output * 255.0).round().astype(np.uint8)
            
            # è½¬æ¢å›BGRæ ¼å¼ä¾›OpenCVä½¿ç”¨
            output_bgr = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)
            
            # æ¸…ç†GPUç¼“å­˜
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            return output_bgr
            
        except Exception as e:
            print(f"âŒ å›¾åƒå¢å¼ºå¤±è´¥: {e}")
            return None
    
    def process_image(self, input_path, output_dir="results", quality=90):
        """å¤„ç†å›¾åƒ"""
        if not self.is_initialized:
            print("âŒ æœåŠ¡æœªåˆå§‹åŒ–ï¼")
            return None
            
        start_time = time.time()
        
        try:
            # æ£€æŸ¥è¾“å…¥
            if not os.path.exists(input_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                return None
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            imgname = os.path.splitext(os.path.basename(input_path))[0]
            output_path = os.path.join(output_dir, f"ESR-{imgname}.webp")
            
            print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {input_path}")
            
            # åŠ è½½å›¾åƒ
            load_start = time.time()
            img = cv2.imread(input_path, cv2.IMREAD_COLOR)
            if img is None:
                print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {input_path}")
                return None
            
            original_shape = img.shape
            load_time = time.time() - load_start
            
            # è°ƒæ•´å¤§å°
            resize_start = time.time()
            img_resized, scale_factor = self.resize_image_if_needed(img)
            resized_shape = img_resized.shape
            resize_time = time.time() - resize_start
            
            # å¢å¼ºå›¾åƒ
            enhance_start = time.time()
            output_img = self.enhance_image(img_resized)
            enhance_time = time.time() - enhance_start
            
            if output_img is None:
                return None
            
            output_shape = output_img.shape
            
            # ä¿å­˜å›¾åƒ
            save_start = time.time()
            # output_imgå·²ç»æ˜¯BGRæ ¼å¼ï¼Œè½¬æ¢ä¸ºRGBç”¨äºPILä¿å­˜
            output_rgb = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(output_rgb)
            pil_img.save(output_path, "WEBP", quality=quality, method=6)
            save_time = time.time() - save_start
            
            # æ€»æ—¶é—´
            total_time = time.time() - start_time
            
            # è¾“å‡ºç»“æœ
            print(f"âœ… å¤„ç†å®Œæˆ!")
            print(f"   ğŸ“¥ è¾“å…¥: {original_shape[1]}Ã—{original_shape[0]} â†’ {resized_shape[1]}Ã—{resized_shape[0]}")
            print(f"   ğŸ“¤ è¾“å‡º: {output_shape[1]}Ã—{output_shape[0]} (4å€æ”¾å¤§)")
            print(f"   ğŸ’¾ ä¿å­˜ä¸º: {output_path}")
            print(f"   ğŸ¨ è´¨é‡: {quality}%")
            if self.device == 'cuda':
                print(f"   ğŸ® GPUæ˜¾å­˜å³°å€¼: {torch.cuda.max_memory_allocated() / 1024**2:.1f}MB")
            print(f"   â±ï¸  æ—¶é•¿åˆ†æ:")
            print(f"      - å›¾åƒåŠ è½½: {load_time:.3f}s")
            print(f"      - å›¾åƒè°ƒæ•´: {resize_time:.3f}s")
            print(f"      - AIå¢å¼º: {enhance_time:.3f}s")
            print(f"      - æ–‡ä»¶ä¿å­˜: {save_time:.3f}s")
            print(f"      - æ€»è®¡: {total_time:.3f}s")
            
            # é‡ç½®æ˜¾å­˜ç»Ÿè®¡
            if self.device == 'cuda':
                torch.cuda.reset_peak_memory_stats()
            
            return output_path
            
        except Exception as e:
            error_time = time.time() - start_time
            print(f"âŒ å¤„ç†å¤±è´¥ (è€—æ—¶{error_time:.2f}s): {str(e)}")
            return None

def main():
    """ä¸»æœåŠ¡å¾ªç¯"""
    print("=" * 60)
    print("ğŸ¯ ç®€åŒ–GPUå›¾åƒæ”¾å¤§æœåŠ¡")
    print("=" * 60)
    
    # é…ç½®
    model_path = "RealESRGAN_x4plus_anime_6B.pth"
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    # åˆå§‹åŒ–æœåŠ¡
    service = SimpleGPUUpscaler(model_path=model_path, device='auto')
    
    if not service.is_initialized:
        print("âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æœåŠ¡å·²å¯åŠ¨ï¼")
    print("ğŸ’¡ æç¤º: è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºæœåŠ¡")
    print("ğŸ’¡ é»˜è®¤è®¾ç½®: 4å€æ”¾å¤§ï¼Œ90%è´¨é‡WebPæ ¼å¼")
    print("=" * 60)
    
    # æœåŠ¡å¾ªç¯
    processed_count = 0
    total_processing_time = 0
    
    while True:
        try:
            print(f"\nğŸ“‚ å·²å¤„ç† {processed_count} å¼ å›¾ç‰‡")
            input_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            
            if input_path.lower() in ['quit', 'exit', 'q']:
                print(f"\nğŸ‘‹ æœåŠ¡ç»“æŸï¼å…±å¤„ç†äº† {processed_count} å¼ å›¾ç‰‡")
                if processed_count > 0:
                    avg_time = total_processing_time / processed_count
                    print(f"ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s/å¼ ")
                break
            
            if not input_path:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„å›¾ç‰‡è·¯å¾„")
                continue
            
            input_path = input_path.strip('"\'')
            
            start_time = time.time()
            result = service.process_image(input_path, "results", 90)
            process_time = time.time() - start_time
            
            if result:
                processed_count += 1
                total_processing_time += process_time
                
        except KeyboardInterrupt:
            print(f"\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼å…±å¤„ç†äº† {processed_count} å¼ å›¾ç‰‡")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
